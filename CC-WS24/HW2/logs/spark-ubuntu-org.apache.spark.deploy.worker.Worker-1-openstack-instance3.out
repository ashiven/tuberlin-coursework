Spark Command: /usr/local/java8/bin/java -cp /usr/local/spark/conf/:/usr/local/spark/jars/* -Xmx1g org.apache.spark.deploy.worker.Worker --webui-port 8081 spark://10.0.0.77:7077
========================================
Using Spark's default log4j profile: org/apache/spark/log4j2-defaults.properties
24/12/02 22:02:17 INFO Worker: Started daemon with process name: 2361@localhost
24/12/02 22:02:17 INFO SignalUtils: Registering signal handler for TERM
24/12/02 22:02:17 INFO SignalUtils: Registering signal handler for HUP
24/12/02 22:02:17 INFO SignalUtils: Registering signal handler for INT
24/12/02 22:02:27 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
24/12/02 22:02:27 INFO SecurityManager: Changing view acls to: ubuntu
24/12/02 22:02:27 INFO SecurityManager: Changing modify acls to: ubuntu
24/12/02 22:02:27 INFO SecurityManager: Changing view acls groups to: 
24/12/02 22:02:27 INFO SecurityManager: Changing modify acls groups to: 
24/12/02 22:02:27 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users with view permissions: ubuntu; groups with view permissions: EMPTY; users with modify permissions: ubuntu; groups with modify permissions: EMPTY
24/12/02 22:02:48 INFO Utils: Successfully started service 'sparkWorker' on port 33546.
24/12/02 22:02:48 INFO Worker: Worker decommissioning not enabled.
24/12/02 22:02:48 INFO Worker: Starting Spark worker 10.0.0.80:33546 with 2 cores, 2.0 GiB RAM
24/12/02 22:02:48 INFO Worker: Running Spark version 3.4.4
24/12/02 22:02:48 INFO Worker: Spark home: /usr/local/spark
24/12/02 22:02:48 INFO ResourceUtils: ==============================================================
24/12/02 22:02:48 INFO ResourceUtils: No custom resources configured for spark.worker.
24/12/02 22:02:48 INFO ResourceUtils: ==============================================================
24/12/02 22:02:48 INFO JettyUtils: Start Jetty 10.0.0.80:8081 for WorkerUI
24/12/02 22:02:48 INFO Utils: Successfully started service 'WorkerUI' on port 8081.
24/12/02 22:02:49 INFO WorkerWebUI: Bound WorkerWebUI to 10.0.0.80, and started at http://10.0.0.80:8081
24/12/02 22:02:49 INFO Worker: Connecting to master 10.0.0.77:7077...
24/12/02 22:02:49 INFO TransportClientFactory: Successfully created connection to /10.0.0.77:7077 after 63 ms (0 ms spent in bootstraps)
24/12/02 22:02:49 INFO Worker: Successfully registered with master spark://10.0.0.77:7077
24/12/02 22:04:29 INFO Worker: Asked to launch executor app-20241202220430-0000/1 for JavaSparkPi
24/12/02 22:04:29 INFO SecurityManager: Changing view acls to: ubuntu
24/12/02 22:04:29 INFO SecurityManager: Changing modify acls to: ubuntu
24/12/02 22:04:29 INFO SecurityManager: Changing view acls groups to: 
24/12/02 22:04:29 INFO SecurityManager: Changing modify acls groups to: 
24/12/02 22:04:29 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users with view permissions: ubuntu; groups with view permissions: EMPTY; users with modify permissions: ubuntu; groups with modify permissions: EMPTY
24/12/02 22:04:29 INFO ExecutorRunner: Launch command: "/usr/local/java8/bin/java" "-cp" "/usr/local/spark/conf/:/usr/local/spark/jars/*" "-Xmx1024M" "-Dspark.driver.port=45093" "-Djava.net.preferIPv6Addresses=false" "-XX:+IgnoreUnrecognizedVMOptions" "--add-opens=java.base/java.lang=ALL-UNNAMED" "--add-opens=java.base/java.lang.invoke=ALL-UNNAMED" "--add-opens=java.base/java.lang.reflect=ALL-UNNAMED" "--add-opens=java.base/java.io=ALL-UNNAMED" "--add-opens=java.base/java.net=ALL-UNNAMED" "--add-opens=java.base/java.nio=ALL-UNNAMED" "--add-opens=java.base/java.util=ALL-UNNAMED" "--add-opens=java.base/java.util.concurrent=ALL-UNNAMED" "--add-opens=java.base/java.util.concurrent.atomic=ALL-UNNAMED" "--add-opens=java.base/jdk.internal.ref=ALL-UNNAMED" "--add-opens=java.base/sun.nio.ch=ALL-UNNAMED" "--add-opens=java.base/sun.nio.cs=ALL-UNNAMED" "--add-opens=java.base/sun.security.action=ALL-UNNAMED" "--add-opens=java.base/sun.util.calendar=ALL-UNNAMED" "--add-opens=java.security.jgss/sun.security.krb5=ALL-UNNAMED" "-Djdk.reflect.useDirectMethodHandle=false" "org.apache.spark.executor.CoarseGrainedExecutorBackend" "--driver-url" "spark://CoarseGrainedScheduler@10.0.0.77:45093" "--executor-id" "1" "--hostname" "10.0.0.80" "--cores" "2" "--app-id" "app-20241202220430-0000" "--worker-url" "spark://Worker@10.0.0.80:33546" "--resourceProfileId" "0"
24/12/02 22:14:35 INFO Worker: Asked to kill executor app-20241202220430-0000/1
24/12/02 22:14:35 INFO ExecutorRunner: Runner thread for executor app-20241202220430-0000/1 interrupted
24/12/02 22:14:35 INFO ExecutorRunner: Killing process!
24/12/02 22:14:36 INFO Worker: Executor app-20241202220430-0000/1 finished with state KILLED exitStatus 0
24/12/02 22:14:36 INFO ExternalShuffleBlockResolver: Clean up non-shuffle and non-RDD files associated with the finished executor 1
24/12/02 22:14:36 INFO ExternalShuffleBlockResolver: Executor is not registered (appId=app-20241202220430-0000, execId=1)
24/12/02 22:14:36 INFO ExternalShuffleBlockResolver: Application app-20241202220430-0000 removed, cleanupLocalDirs = true
24/12/02 22:14:36 INFO Worker: Cleaning up local directories for application app-20241202220430-0000
